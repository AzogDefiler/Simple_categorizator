{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import InceptionV3\n",
    "from keras.applications import Xception # TensorFlow ONLY\n",
    "from keras.applications import inception_resnet_v2\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import VGG19\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from PIL import Image\n",
    "import operator\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "from keras.layers.convolutional import AtrousConvolution1D\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dropout, BatchNormalization, Activation, Add, Conv2DTranspose, ZeroPadding1D\n",
    "import keras\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Merge, Dropout, UpSampling1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, concatenate, LSTM, Dense, RepeatVector, Embedding, TimeDistributed\n",
    "from keras.layers import LSTM, GRU, MaxPooling1D\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import Dense, Reshape\n",
    "from keras.layers.core import Activation, Dense, Dropout, Flatten, Lambda\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D, GlobalAveragePooling2D\n",
    "import keras.backend as K\n",
    "\n",
    "import pandas as pd\n",
    "import pycurl\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import InceptionV3\n",
    "from keras.applications import Xception # TensorFlow ONLY\n",
    "from keras.applications import inception_resnet_v2\n",
    "from keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "from keras import regularizers\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob as glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csvs = glob.glob('*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['68080.csv',\n",
       " '68056.csv',\n",
       " '56304.csv',\n",
       " '57433.csv',\n",
       " '55731.csv',\n",
       " '56034.csv',\n",
       " '55939.csv',\n",
       " '57439.csv',\n",
       " '54618.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aminov/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df =  pd.read_csv(csvs[0], sep=' *huh',header=None)\n",
    "from sklearn import utils\n",
    "val_cnt = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aminov/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df = utils.shuffle(df)\n",
    "df_train = df[:-val_cnt]\n",
    "df_test = df[-val_cnt:]\n",
    "\n",
    "for cs in csvs[1:]:\n",
    "    buf = pd.read_csv(cs, sep=' *huh',header=None)\n",
    "    buf = utils.shuffle(buf)\n",
    "    df_train = df_train.append(buf[:-val_cnt], ignore_index=True)\n",
    "    df_test = df_test.append(buf[-val_cnt:], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = utils.shuffle(df_train)\n",
    "df_test = utils.shuffle(df_test)\n",
    "\n",
    "def clear_dataset(df_train):\n",
    "    for i,val in df_train.iterrows():\n",
    "        #--------0---------\n",
    "        dir_ = str(val[0][:-1].strip())\n",
    "\n",
    "        #--------3---------\n",
    "        shit_len = len('/var/spool/data/www')\n",
    "        buf = val[3][1:].strip()\n",
    "        path = buf[shit_len:]\n",
    "        name = path.split('/')[-1]\n",
    "        img_path = dir_+'/'+name+'.jpg'\n",
    "\n",
    "        #--------2--------- \n",
    "        name = val[2][1:-1].strip().lower()\n",
    "\n",
    "        #------------------\n",
    "        df_train.at[i, 0] = dir_\n",
    "        df_train.at[i, 3] = img_path\n",
    "        df_train.at[i, 2] = name\n",
    "        \n",
    "clear_dataset(df_train)\n",
    "clear_dataset(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## -------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = sorted(df_train[0].unique())\n",
    "label_to_onehot = dict((c, to_categorical(i, num_classes=len(categories))) for i, c in enumerate(categories))\n",
    "label_to_int = dict((c, i) for i, c in enumerate(categories))\n",
    "int_to_label = dict((i, c) for i, c in enumerate(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphabet = ' абвгдеёжзийклмнопрстуфхцчшщъыьэюяabcdefghijklmnopqrstuvwxyz0123456789-,;.’!?:\\'\"/\\\\&|_@#$%°«^&ø*~№`+—-=<>()[]{}'\n",
    "\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 400\n",
    "\n",
    "def char_one_hot(data):\n",
    "    for _ in range(maxlen-len(data)):\n",
    "        data+=' '\n",
    "    data = data.lower()\n",
    "    integer_encoded = [char_to_int[char] if char in char_to_int else char_to_int[' '] for char in data ]\n",
    "\n",
    "    onehot_encoded = list()\n",
    "    for value in integer_encoded:\n",
    "        letter = [0 for _ in range(len(alphabet))]\n",
    "        letter[value] = 1\n",
    "        onehot_encoded.append(letter)\n",
    "        \n",
    "    return integer_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = Xception(weights=\"imagenet\")\n",
    "for l in base_model.layers:\n",
    "    l.trainable = True\n",
    "\n",
    "img_x = base_model.layers[-2].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aminov/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, activation=\"relu\", kernel_regularizer=<keras.reg...)`\n"
     ]
    }
   ],
   "source": [
    "def create_conv_model():\n",
    "    \n",
    "    inputs = Input(shape=(None,), name='sent_input', dtype='int64')\n",
    "    x = Embedding(len(alphabet), 64, input_length=None)(inputs)\n",
    "       \n",
    "    frst_conv = Conv1D(32, 1, activation='relu', padding='same')(x)\n",
    "    \n",
    "    conv1 = Conv1D(64, 2, activation='relu', padding='same')(x)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = MaxPooling1D(3, strides=1, padding='same')(conv1)   \n",
    "    conv1 = Conv1D(64, 2, activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = MaxPooling1D(3, strides=1, padding='same')(conv1)   \n",
    "    conv1 = Conv1D(128, 2, activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = MaxPooling1D(3, strides=1, padding='same')(conv1)   \n",
    "    conv1 = Conv1D(128, 2, activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = MaxPooling1D(3, strides=1, padding='same')(conv1)   \n",
    "    conv1 = Conv1D(256, 2, activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = MaxPooling1D(3, strides=1, padding='same')(conv1)   \n",
    "    conv1 = Conv1D(512, 2, activation='relu', padding='same')(conv1)\n",
    "    end = BatchNormalization()(conv1)\n",
    "   \n",
    "    avg = GlobalAveragePooling1D()(end)\n",
    "    \n",
    "    concat_x = Dense(256,activation='relu', W_regularizer=l2(0.001))(avg)#(concat_x)\n",
    "    \n",
    "    output = Dense(len(categories), activation='softmax')(concat_x)\n",
    "   \n",
    "    #model = Model(inputs=[base_model.input, inputs], outputs = output)\n",
    "    model = Model(inputs = inputs, outputs = output)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "model = create_conv_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.00002, beta_1=0.9, beta_2=0.999, epsilon=1e-8), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sent_input (InputLayer)      (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, None, 64)          7040      \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, None, 64)          8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, None, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, None, 64)          8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, None, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, None, 128)         16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, None, 128)         32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, None, 256)         65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, None, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, None, 512)         262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, None, 512)         2048      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_5 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 9)                 2313      \n",
      "=================================================================\n",
      "Total params: 539,657\n",
      "Trainable params: 537,353\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BS = 32\n",
    "def generator_data(df_train):\n",
    "    while True:\n",
    "        step = 0\n",
    "        for b in range(int(len(df_train)/BS)):\n",
    "            itr=0\n",
    "            X = np.zeros((BS,maxlen))\n",
    "            Y = np.zeros((BS,len(categories)))\n",
    "            for i, val in df_train[step:step+BS].iterrows():\n",
    "                try:\n",
    "                    y = label_to_onehot[val[0]]\n",
    "\n",
    "                    text_x = np.array([char_one_hot(val[2])])\n",
    "\n",
    "                    X[itr]=text_x\n",
    "                    Y[itr]=y\n",
    "\n",
    "                    #yield ( text_x, np.array([y]))\n",
    "                except Exception as ex:\n",
    "                    pass\n",
    "                itr+=1\n",
    "                \n",
    "            step+=BS\n",
    "            yield (X,Y)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n",
      "236/236 [==============================] - 33s 141ms/step - loss: 0.6192 - acc: 0.8922 - val_loss: 0.7232 - val_acc: 0.8539\n",
      "Epoch 2/17\n",
      "236/236 [==============================] - 29s 124ms/step - loss: 0.4882 - acc: 0.9300 - val_loss: 0.6225 - val_acc: 0.8986\n",
      "Epoch 3/17\n",
      "236/236 [==============================] - 29s 123ms/step - loss: 0.4019 - acc: 0.9630 - val_loss: 0.4791 - val_acc: 0.9456\n",
      "Epoch 4/17\n",
      "236/236 [==============================] - 29s 124ms/step - loss: 0.3402 - acc: 0.9839 - val_loss: 0.5285 - val_acc: 0.9167\n",
      "Epoch 5/17\n",
      "236/236 [==============================] - 29s 124ms/step - loss: 0.2960 - acc: 0.9915 - val_loss: 0.4905 - val_acc: 0.9287\n",
      "Epoch 6/17\n",
      "236/236 [==============================] - 29s 123ms/step - loss: 0.2619 - acc: 0.9945 - val_loss: 0.4771 - val_acc: 0.9220\n",
      "Epoch 7/17\n",
      "236/236 [==============================] - 29s 124ms/step - loss: 0.2333 - acc: 0.9962 - val_loss: 0.3633 - val_acc: 0.9502\n",
      "Epoch 8/17\n",
      "236/236 [==============================] - 29s 125ms/step - loss: 0.2079 - acc: 0.9973 - val_loss: 0.3259 - val_acc: 0.9614\n",
      "Epoch 9/17\n",
      "236/236 [==============================] - 29s 123ms/step - loss: 0.1850 - acc: 0.9980 - val_loss: 0.3275 - val_acc: 0.9386\n",
      "Epoch 10/17\n",
      "236/236 [==============================] - 29s 124ms/step - loss: 0.1641 - acc: 0.9985 - val_loss: 0.2854 - val_acc: 0.9508\n",
      "Epoch 11/17\n",
      "236/236 [==============================] - 29s 124ms/step - loss: 0.1451 - acc: 0.9989 - val_loss: 0.2532 - val_acc: 0.9565\n",
      "Epoch 12/17\n",
      "236/236 [==============================] - 29s 124ms/step - loss: 0.1278 - acc: 0.9992 - val_loss: 0.1730 - val_acc: 0.9805\n",
      "Epoch 13/17\n",
      "236/236 [==============================] - 29s 124ms/step - loss: 0.1122 - acc: 0.9994 - val_loss: 0.1631 - val_acc: 0.9791\n",
      "Epoch 14/17\n",
      "236/236 [==============================] - 29s 124ms/step - loss: 0.0981 - acc: 0.9995 - val_loss: 0.1489 - val_acc: 0.9762\n",
      "Epoch 15/17\n",
      "236/236 [==============================] - 29s 123ms/step - loss: 0.0855 - acc: 0.9996 - val_loss: 0.1183 - val_acc: 0.9895\n",
      "Epoch 16/17\n",
      "236/236 [==============================] - 29s 124ms/step - loss: 0.0743 - acc: 0.9997 - val_loss: 0.1064 - val_acc: 0.9902\n",
      "Epoch 17/17\n",
      "236/236 [==============================] - 29s 123ms/step - loss: 0.0645 - acc: 0.9998 - val_loss: 0.0790 - val_acc: 0.9953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4fcd575710>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator_data(df_train), \n",
    "                    steps_per_epoch=int(len(df_train)/BS),\n",
    "                    validation_data=generator_data(df_test),\n",
    "                    validation_steps=int(len(df_test)/BS),\n",
    "                    epochs=17\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.07902339065358752, 0.9952877050354367]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(generator_data(df_test),int(len(df_test)/BS))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
